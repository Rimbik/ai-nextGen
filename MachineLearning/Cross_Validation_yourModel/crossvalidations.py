# -*- coding: utf-8 -*-
"""CrossValidations.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1amvJn3pnO3ofiOsKpDODNi3Lb9JHvBp-
"""

### Cross Validation Technique using various algo:
https://neptune.ai/blog/cross-validation-in-machine-learning-how-to-do-it-right

-Hold-out
-K-folds
-Leave-one-out
-Leave-p-out
-Stratified K-folds
-Repeated K-folds
-Nested K-folds
-Time series CV

import numpy as np
# from sklearn.model_selection import KFold, cross_val_score
from sklearn.linear_model import LogisticRegression
from sklearn.datasets import load_iris

# Load a sample dataset (Iris dataset)
data = load_iris()
X = data.data
y = data.target

def show_score(validationType) :
    # SHOW Score ----------------------------
    # Perform cross-validation and get accuracy scores for each fold
    cv_scores = cross_val_score(model, X, y, cv=validationType, scoring='accuracy')
    # Print the accuracy for each fold
    print(f"Accuracy for each fold: {cv_scores}")
    # Print the average accuracy across all folds
    print(f"Average accuracy: {cv_scores.mean():.2f}")

import pandas as pd
df = pd.DataFrame(X, columns=data.feature_names)
df.head()

# normal regression
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
model = LogisticRegression()
model.fit(X_train, y_train)

accuracy = model.score(X_test, y_test)
print(f"Accuracy: {accuracy:.2f}")

#----------------------------------------------------------
# k-fold > cross validation
#----------------------------------------------------------
from sklearn.model_selection import KFold, cross_val_score
# Initialize the model
model = LogisticRegression(max_iter=200)
# Define the k-fold cross-validation method (e.g., 5-fold)
crossValType = KFold(n_splits=5, shuffle=True, random_state=42)

# SHOW Score ----------------------------
# Perform cross-validation and get accuracy scores for each fold
cv_scores = cross_val_score(model, X, y, cv=crossValType, scoring='accuracy')
# Print the accuracy for each fold
print(f"Accuracy for each fold: {cv_scores}")
# Print the average accuracy across all folds
print(f"Average accuracy: {cv_scores.mean():.2f}")

#----------------------------------------------------------
# LeaveOneOut > cross validation
#----------------------------------------------------------

#Initialize the model
from sklearn.model_selection import LeaveOneOut, cross_val_score
model = LogisticRegression(max_iter=200)
# Define the Leave-One-Out Cross-Validation method
crossValType = LeaveOneOut()

show_score(crossValType)

#----------------------------------------------------------
# LeavePOut > cross validation
#----------------------------------------------------------
from sklearn.model_selection import LeavePOut, cross_val_score
# Initialize the model
model = LogisticRegression(max_iter=200)
# Define the Leave-p-out Cross-Validation method (e.g., leave 2 data points out)
p = 2
crossValType = LeavePOut(p)

show_score(crossValType)

#----------------------------------------------------------
# RepeatedKFold > cross validation
#----------------------------------------------------------
from sklearn.model_selection import RepeatedKFold, cross_val_score

# Initialize the model
model = LogisticRegression(max_iter=200)
# Define the Repeated K-Fold Cross-Validation method (e.g., 5-fold, repeated 3 times)
crossValidationType = RepeatedKFold(n_splits=5, n_repeats=3, random_state=42)

show_score(crossValType)

#----------------------------------------------------------
# StratifiedKFold > cross validation
#----------------------------------------------------------
from sklearn.model_selection import StratifiedKFold, cross_val_score
# Initialize the model
model = LogisticRegression(max_iter=200)

# Define the Stratified K-Fold Cross-Validation method (e.g., 5-fold)
crossValType = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

# Perform cross-validation and get accuracy scores for each fold
cv_scores = cross_val_score(model, X, y, cv=crossValType, scoring='accuracy')

show_score(crossValType)

#----------------------------------------------------------
# Nested K-folds > cross validation
#----------------------------------------------------------
from sklearn.model_selection import GridSearchCV, cross_val_score

# Initialize the model
model = LogisticRegression(max_iter=200)

# Define the hyperparameters to tune (for example, the regularization parameter C)
param_grid = {'C': [0.01, 0.1, 1, 10, 100]}

# Define the outer and inner k-folds
outer_cv = KFold(n_splits=5, shuffle=True, random_state=42)
inner_cv = KFold(n_splits=5, shuffle=True, random_state=42)

# Set up GridSearchCV for the inner cross-validation loop to tune hyperparameters
grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=inner_cv, scoring='accuracy')

# Perform nested cross-validation
nested_scores = cross_val_score(grid_search, X, y, cv=outer_cv, scoring='accuracy')

# Print the accuracy for each outer fold
print(f"Accuracy for each outer fold: {nested_scores}")

# Print the average accuracy across all outer folds
print(f"Average accuracy: {nested_scores.mean():.2f}")

#----------------------------------------------------------
# TimeSeriesSplit > cross validation
#----------------------------------------------------------
import numpy as np
from sklearn.model_selection import TimeSeriesSplit, cross_val_score
from sklearn.linear_model import LinearRegression
from sklearn.datasets import fetch_openml

# Example: Load a time series dataset
# Here we use a simple dataset (you can replace this with your own time series data)

data = fetch_openml('AirQuality', version=3)

X = np.array(data.data[['Time']])  # Using 'Time' as the feature for simplicity
y = np.array(data.data['Value'])  # 'Value' is the target

# Initialize the model
model = LinearRegression()

# Define the TimeSeriesSplit (e.g., 5 splits)
tscv = TimeSeriesSplit(n_splits=5)

# Perform time series cross-validation and get R-squared scores for each split
cv_scores = cross_val_score(model, X, y, cv=tscv, scoring='r2')

# Print the R-squared score for each fold
print(f"R-squared for each fold: {cv_scores}")

# Print the average R-squared across all folds
print(f"Average R-squared: {cv_scores.mean():.2f}")

